The core process for **Description to Code (D2C)** involves defining the goal in natural language (the "Description") and generating the resulting program code. To achieve high-quality D2C, the specification must be highly structured and tailored to the specific LLM's strengths and the complexity of the task, ranging from simple functions to entire system designs.

Here are three distinct D2C specification outlines, drawing on specialized prompt engineering techniques and LLM capabilities:

---

## 1. General High-Quality Code Generation Specification (Focus: Function/Endpoint/Component)

This outline incorporates the **CARE framework** (Context, Action, Result, Evaluation) and general best practices to ensure clear, high-quality output suitable for mainstream Code LLMs like Codex/Copilot, GPT, and specialized CodeLlama variants.

| Component | Purpose & Details | Key Elements from Sources |
| :--- | :--- | :--- |
| **Context (C)** | Provides the background, purpose, and assumptions needed for the AI's decision-making. | **Technical Persona:** Assign a role (e.g., "Act as a senior security engineer"). **Problem Domain:** Specific problem domain and current codebase characteristics. **Existing Patterns:** Explicit reference to implementation patterns (e.g., using the same functional approach as another method). **Constraints:** Specify language, framework, and version (e.g., "Python 3.9," "FastAPI 0.95"). |
| **Action (A) / Functional Requirements** | Detailed description of what the code must achieve. | **Requirements:** Clear description of inputs, outputs, and expected processing logic. Use `@references` to point the model to specific files or functions for context. |
| **Action (A) / Few-Shot Examples** | Concrete input/output scenarios demonstrating expected behavior. | **Examples:** Provide 2-3 concrete input/output examples of desired functionality. **Complex Inputs:** Focus on prompts with **more complex inputs**, as simple or edge case examples provide little benefit. (Note: Few-shot input-output examples are a component of the prompt template for D2C tasks). |
| **Result (R) / Outputs & Artifacts** | Defines the expected return type and structure of the output. | **Formatting:** Specify EXACTLY how the output should be structured, using Markdown, tables, or JSON. YAML can be used instead of JSON for greater cost/time efficiency, especially for long structured outputs. **Chaining:** Use **Chain of Thought Prompting** to request sequential reasoning stages (Conceptual approach, Pseudocode, Implementation details) before the final code. |
| **Evaluation (E) / Validation & NFRs** | How the output should be validated and what non-functional concerns must be addressed. | **Acceptance Criteria:** Must be testable and measurable (e.g., "All existing tests pass"). **Edge Cases:** Explicitly list boundary values and error conditions (e.g., handling empty files, concurrent access). **Non-Functional Requirements (NFRs):** Specify performance (e.g., "Must respond within 200ms"), security (e.g., "OWASP expertise"), and maintainability constraints. |

---

## 2. Claude-Optimized Specification (Focus: Complex Reasoning & Agentic Tasks)

This outline is based on the 10-point structured template recommended for Claude models, which are specifically trained to handle massive context, follow complex instructions, and engage in explicit reasoning.

| Component | Purpose & Details | Recommended Action (Claude-Specific) |
| :--- | :--- | :--- |
| **Setup & Role** | Defines the model's identity and communication style. | **Task Context:** Clearly define WHO the AI is and WHAT role it is playing (e.g., "You're a senior marketing director writing to the CEO"). **Tone Context:** Specify the exact tone (e.g., "Professional but approachable"). |
| **Pre-Computation & Context** | Provides the model with all necessary background information for deep understanding. | **Background Data/Documents:** Feed Claude relevant context, annual reports, or style guides. Claude is specifically trained to handle **massive context windows** (200K+ tokens) and utilize this background information. **Layering:** Front-load critical information (Context, Tone, Background, Rules). |
| **Rules & Constraints** | Maximizes output focus and consistency by setting boundaries. | **Detailed Task Description & Rules:** Set boundaries, such as output length (e.g., "Never exceed 500 words"). Claude "LOVES constraints," and setting rules results in more focused output. |
| **Demonstrations** | Teaches the model the desired pattern and quality level. | **Examples:** Include 1-2 examples of what good output looks like. |
| **Iterative Context** | Maintains continuity in multi-turn engagements. | **Conversation History:** Include relevant previous exchanges if the task is part of an ongoing conversation. |
| **The Immediate Ask** | Focuses the model on the final deliverable. | **Immediate Task Description (Current Ask):** Clearly state the specific deliverable you want RIGHT NOW. |
| **Reasoning Activation** | Engages the modelâ€™s deeper cognitive processes. | **Thinking Step-by-Step:** Add instructions like **"Think about your answer first before responding"** or **"Take a deep breath and work through this systematically"** to activate chain-of-thought and reasoning capabilities. |
| **Output Constraints** | Ensures the output is immediately usable and parsable. | **Output Formatting:** Specify the EXACT required output structure (e.g., Markdown, XML tags, bullet points). **Prefilled Response (Advanced):** Start Claude's response for them to guide the output style. |

---

## 3. Progressive System Development Specification (Focus: Architecture & Large-Scale D2C)

This outline uses the **Progressive Prompting** method favored by the specialized "Software Engineer GPT" and architectural prompt templates, breaking down the Description to Code (D2C) task into verifiable design stages.

| Stage/Step | Description to Code Prompt Outline | Relevant LLMs & Context |
| :--- | :--- | :--- |
| **Stage 1: Requirements Refinement** | **Goal:** Refine detailed requirements documents (e.g., use cases) into functional components. | LLMs must receive detailed requirements as input, not just brief descriptions. The model is asked to "refine requirements into detailed functional requirements". |
| **Stage 2: Design Modeling** | **Goal:** Translate functional requirements into a structured design model (Object-Oriented Design). | LLM needs instructions/knowledge base on heuristics for requirements analysis, object-oriented design, and test-driven development. Prompt should ask the LLM to **identify key classes, assign responsibilities, and provide properties and operations**. |
| **Stage 3: Architectural Synthesis** | **Goal:** Propose high-level architecture, interaction patterns, and key tradeoffs. | Prompt uses LLM as a "senior systems architect". Request the model to: **1. Propose an architecture that prioritizes constraints** (e.g., security and scalability). **2. Generate a Tradeoff Matrix** comparing different solutions (e.g., data storage options) against critical criteria (cost, consistency, operational complexity). **3. Output structured documentation** like an **Architecture Decision Record (ADR)** or a **System Architecture Specification Template** in Markdown format. |
| **Stage 4: Implementation Preparation** | **Goal:** Generate verifiable test cases before generating the final code. | Prompt the LLM to generate **unit test cases** for a specific class method based on the OOD and functional requirements. This acts as a final check before code generation. |
| **Stage 5: Final Code Generation (D2C)** | **Goal:** Produce the final implementation code snippet or function body. | Prompt the LLM to generate implementation code based on the **intermediate artifacts** or "chain of thoughts" generated in the previous steps. For larger tasks, advanced templates like the **Microservice Specification Template** can be used, detailing API contracts, dependencies, and deployment requirements. |
